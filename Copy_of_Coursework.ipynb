{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM37CfTFes+RZ/Ru8oeq71E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkyHaines/IMLO/blob/main/Copy_of_Coursework%3F%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CIFAR 10 dataset contains 60,000 3x32x32 colour images, with 10 classes."
      ],
      "metadata": {
        "id": "-84D_fD6rDLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Need to look into how this works, perhaps i could tweak it to improve accuracy?\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.3),\n",
        "     transforms.RandomVerticalFlip(p=0.3),\n",
        "     transforms.RandomCrop(32, padding=3),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download training and testing data\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=test_transform\n",
        ")"
      ],
      "metadata": {
        "id": "VZi8zCXJrav8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I need to experiment with batch size. (The number of images processed before updating the weights).\n",
        "\n",
        "As I understand it,\n",
        "Larger batch size : Faster training, lower accuracy\n",
        "Smaller batch size: Slower training, higher accuracy\n",
        "\n",
        "So I'm going to do some trial and error I think, to get the batch size at a point where I use up just under the whole 4 training hours, with the highest accuracy :)\n",
        "\n",
        "Contextualise: There are 50,000 training imgs, so I'm going to try a batch size of 100 for now? (As its a multiple, I assume it helps somehow?)\n",
        "UPDATED: Changed to 64, research suggests it helps with runtime to have it as a power of 2, for parallelism. Will take this into account for further optimisation."
      ],
      "metadata": {
        "id": "1fwoUvIGtKON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "MgLYf_Y9uPpl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I need to define the nn architecture/structure? I think I need to use a CNN rather than a regular NN because it's for images rather than numerical data"
      ],
      "metadata": {
        "id": "g1c8jRGF4Rz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # First layer? Has 3 input channels due to RGB\n",
        "    # input tensor = size of prev layer output * filters in prev layer\n",
        "    # output tensor = size of input img * filters\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=8, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=24, out_channels=48,kernel_size=4, stride=1, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=96*3*3, out_features=512)\n",
        "    self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
        "    self.fc3 = nn.Linear(in_features=256, out_features=128)\n",
        "    self.fc4 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool3(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "model = MyCNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkfUE5N64dPX",
        "outputId": "d89387fe-e5fd-4ded-f8c8-9d9cbcc33ca5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyCNN(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(24, 48, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=864, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "8qP-BYDG9P3o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimiser):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      if batch % (len(dataloader) // 6) == 0:\n",
        "        loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "HfS2EQkC-5SR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 75\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n-------------------------------\")\n",
        "  train(train_dataloader, model, loss, optimiser)\n",
        "  test(test_dataloader, model, loss)\n",
        "print(\"Done :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qSwKwo58_VLm",
        "outputId": "820ce95e-a419-45a6-b16d-157cfbbeef59"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "-------------------------------\n",
            "loss: 2.311340  [   16/50000]\n",
            "loss: 2.159935  [ 8336/50000]\n",
            "loss: 2.087691  [16656/50000]\n",
            "loss: 1.840866  [24976/50000]\n",
            "loss: 1.531859  [33296/50000]\n",
            "loss: 1.635286  [41616/50000]\n",
            "loss: 2.282203  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 36.6%, Avg loss: 1.668896 \n",
            "\n",
            "Epoch 2 \n",
            "-------------------------------\n",
            "loss: 2.304444  [   16/50000]\n",
            "loss: 1.670620  [ 8336/50000]\n",
            "loss: 1.690628  [16656/50000]\n",
            "loss: 1.472720  [24976/50000]\n",
            "loss: 1.576468  [33296/50000]\n",
            "loss: 1.759532  [41616/50000]\n",
            "loss: 1.732572  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 42.5%, Avg loss: 1.514786 \n",
            "\n",
            "Epoch 3 \n",
            "-------------------------------\n",
            "loss: 1.363748  [   16/50000]\n",
            "loss: 1.933256  [ 8336/50000]\n",
            "loss: 1.832492  [16656/50000]\n",
            "loss: 1.465516  [24976/50000]\n",
            "loss: 1.539391  [33296/50000]\n",
            "loss: 1.454079  [41616/50000]\n",
            "loss: 1.624002  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 45.1%, Avg loss: 1.464602 \n",
            "\n",
            "Epoch 4 \n",
            "-------------------------------\n",
            "loss: 1.709303  [   16/50000]\n",
            "loss: 1.917578  [ 8336/50000]\n",
            "loss: 1.580131  [16656/50000]\n",
            "loss: 1.182390  [24976/50000]\n",
            "loss: 2.146209  [33296/50000]\n",
            "loss: 1.916045  [41616/50000]\n",
            "loss: 1.451441  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 49.8%, Avg loss: 1.364234 \n",
            "\n",
            "Epoch 5 \n",
            "-------------------------------\n",
            "loss: 1.706531  [   16/50000]\n",
            "loss: 1.426714  [ 8336/50000]\n",
            "loss: 1.486271  [16656/50000]\n",
            "loss: 1.055493  [24976/50000]\n",
            "loss: 1.475086  [33296/50000]\n",
            "loss: 1.397502  [41616/50000]\n",
            "loss: 1.333022  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 53.7%, Avg loss: 1.265668 \n",
            "\n",
            "Epoch 6 \n",
            "-------------------------------\n",
            "loss: 1.085188  [   16/50000]\n",
            "loss: 1.754131  [ 8336/50000]\n",
            "loss: 1.637172  [16656/50000]\n",
            "loss: 1.392002  [24976/50000]\n",
            "loss: 1.025535  [33296/50000]\n",
            "loss: 1.236717  [41616/50000]\n",
            "loss: 1.138039  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 55.5%, Avg loss: 1.210376 \n",
            "\n",
            "Epoch 7 \n",
            "-------------------------------\n",
            "loss: 1.296743  [   16/50000]\n",
            "loss: 1.389466  [ 8336/50000]\n",
            "loss: 1.674895  [16656/50000]\n",
            "loss: 1.119040  [24976/50000]\n",
            "loss: 1.361975  [33296/50000]\n",
            "loss: 1.225511  [41616/50000]\n",
            "loss: 0.914084  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 56.6%, Avg loss: 1.174316 \n",
            "\n",
            "Epoch 8 \n",
            "-------------------------------\n",
            "loss: 0.942415  [   16/50000]\n",
            "loss: 1.696054  [ 8336/50000]\n",
            "loss: 1.252665  [16656/50000]\n",
            "loss: 1.468906  [24976/50000]\n",
            "loss: 1.363416  [33296/50000]\n",
            "loss: 1.698700  [41616/50000]\n",
            "loss: 1.368744  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 59.2%, Avg loss: 1.112628 \n",
            "\n",
            "Epoch 9 \n",
            "-------------------------------\n",
            "loss: 0.711970  [   16/50000]\n",
            "loss: 1.581953  [ 8336/50000]\n",
            "loss: 1.307970  [16656/50000]\n",
            "loss: 1.288993  [24976/50000]\n",
            "loss: 1.170463  [33296/50000]\n",
            "loss: 1.083710  [41616/50000]\n",
            "loss: 0.868903  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 58.8%, Avg loss: 1.107762 \n",
            "\n",
            "Epoch 10 \n",
            "-------------------------------\n",
            "loss: 0.877442  [   16/50000]\n",
            "loss: 1.359075  [ 8336/50000]\n",
            "loss: 0.973795  [16656/50000]\n",
            "loss: 1.113175  [24976/50000]\n",
            "loss: 1.029434  [33296/50000]\n",
            "loss: 1.131730  [41616/50000]\n",
            "loss: 1.340297  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 62.3%, Avg loss: 1.033617 \n",
            "\n",
            "Epoch 11 \n",
            "-------------------------------\n",
            "loss: 1.072471  [   16/50000]\n",
            "loss: 0.868424  [ 8336/50000]\n",
            "loss: 1.270982  [16656/50000]\n",
            "loss: 0.755425  [24976/50000]\n",
            "loss: 1.038621  [33296/50000]\n",
            "loss: 1.138852  [41616/50000]\n",
            "loss: 1.424334  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 63.0%, Avg loss: 1.021614 \n",
            "\n",
            "Epoch 12 \n",
            "-------------------------------\n",
            "loss: 1.000750  [   16/50000]\n",
            "loss: 1.210223  [ 8336/50000]\n",
            "loss: 1.262185  [16656/50000]\n",
            "loss: 1.220195  [24976/50000]\n",
            "loss: 1.300697  [33296/50000]\n",
            "loss: 1.141796  [41616/50000]\n",
            "loss: 0.848488  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 63.8%, Avg loss: 0.997908 \n",
            "\n",
            "Epoch 13 \n",
            "-------------------------------\n",
            "loss: 0.757093  [   16/50000]\n",
            "loss: 0.732451  [ 8336/50000]\n",
            "loss: 0.864834  [16656/50000]\n",
            "loss: 1.071264  [24976/50000]\n",
            "loss: 0.789528  [33296/50000]\n",
            "loss: 1.030081  [41616/50000]\n",
            "loss: 0.948760  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 66.5%, Avg loss: 0.938812 \n",
            "\n",
            "Epoch 14 \n",
            "-------------------------------\n",
            "loss: 1.333970  [   16/50000]\n",
            "loss: 1.112563  [ 8336/50000]\n",
            "loss: 0.622988  [16656/50000]\n",
            "loss: 0.873522  [24976/50000]\n",
            "loss: 1.319398  [33296/50000]\n",
            "loss: 0.975702  [41616/50000]\n",
            "loss: 1.263199  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 66.2%, Avg loss: 0.938837 \n",
            "\n",
            "Epoch 15 \n",
            "-------------------------------\n",
            "loss: 0.892347  [   16/50000]\n",
            "loss: 1.583070  [ 8336/50000]\n",
            "loss: 0.952582  [16656/50000]\n",
            "loss: 1.155391  [24976/50000]\n",
            "loss: 0.676626  [33296/50000]\n",
            "loss: 0.717208  [41616/50000]\n",
            "loss: 0.965944  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 67.6%, Avg loss: 0.905478 \n",
            "\n",
            "Epoch 16 \n",
            "-------------------------------\n",
            "loss: 0.900959  [   16/50000]\n",
            "loss: 1.080861  [ 8336/50000]\n",
            "loss: 0.640448  [16656/50000]\n",
            "loss: 0.835905  [24976/50000]\n",
            "loss: 0.867773  [33296/50000]\n",
            "loss: 1.064193  [41616/50000]\n",
            "loss: 1.142206  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 66.8%, Avg loss: 0.927650 \n",
            "\n",
            "Epoch 17 \n",
            "-------------------------------\n",
            "loss: 0.866023  [   16/50000]\n",
            "loss: 0.828629  [ 8336/50000]\n",
            "loss: 1.043171  [16656/50000]\n",
            "loss: 0.768571  [24976/50000]\n",
            "loss: 0.987067  [33296/50000]\n",
            "loss: 1.036599  [41616/50000]\n",
            "loss: 0.884203  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 67.9%, Avg loss: 0.897785 \n",
            "\n",
            "Epoch 18 \n",
            "-------------------------------\n",
            "loss: 1.000986  [   16/50000]\n",
            "loss: 0.680716  [ 8336/50000]\n",
            "loss: 0.890685  [16656/50000]\n",
            "loss: 0.954257  [24976/50000]\n",
            "loss: 1.329986  [33296/50000]\n",
            "loss: 0.979318  [41616/50000]\n",
            "loss: 0.845109  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 68.3%, Avg loss: 0.871896 \n",
            "\n",
            "Epoch 19 \n",
            "-------------------------------\n",
            "loss: 0.708771  [   16/50000]\n",
            "loss: 0.937341  [ 8336/50000]\n",
            "loss: 0.824135  [16656/50000]\n",
            "loss: 0.863185  [24976/50000]\n",
            "loss: 0.895620  [33296/50000]\n",
            "loss: 0.898984  [41616/50000]\n",
            "loss: 1.295069  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 70.2%, Avg loss: 0.842156 \n",
            "\n",
            "Epoch 20 \n",
            "-------------------------------\n",
            "loss: 0.605892  [   16/50000]\n",
            "loss: 0.682063  [ 8336/50000]\n",
            "loss: 0.656877  [16656/50000]\n",
            "loss: 1.209344  [24976/50000]\n",
            "loss: 1.005652  [33296/50000]\n",
            "loss: 0.808213  [41616/50000]\n",
            "loss: 1.073908  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 70.4%, Avg loss: 0.834006 \n",
            "\n",
            "Epoch 21 \n",
            "-------------------------------\n",
            "loss: 0.994206  [   16/50000]\n",
            "loss: 1.246729  [ 8336/50000]\n",
            "loss: 0.586606  [16656/50000]\n",
            "loss: 0.775501  [24976/50000]\n",
            "loss: 0.749344  [33296/50000]\n",
            "loss: 0.790258  [41616/50000]\n",
            "loss: 0.686128  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 71.1%, Avg loss: 0.806400 \n",
            "\n",
            "Epoch 22 \n",
            "-------------------------------\n",
            "loss: 0.718732  [   16/50000]\n",
            "loss: 0.733770  [ 8336/50000]\n",
            "loss: 0.906653  [16656/50000]\n",
            "loss: 0.706757  [24976/50000]\n",
            "loss: 1.120196  [33296/50000]\n",
            "loss: 0.452851  [41616/50000]\n",
            "loss: 1.031177  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 70.9%, Avg loss: 0.817446 \n",
            "\n",
            "Epoch 23 \n",
            "-------------------------------\n",
            "loss: 1.022946  [   16/50000]\n",
            "loss: 0.508519  [ 8336/50000]\n",
            "loss: 1.027345  [16656/50000]\n",
            "loss: 0.815484  [24976/50000]\n",
            "loss: 0.725859  [33296/50000]\n",
            "loss: 0.940007  [41616/50000]\n",
            "loss: 0.685245  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 72.2%, Avg loss: 0.778868 \n",
            "\n",
            "Epoch 24 \n",
            "-------------------------------\n",
            "loss: 0.664236  [   16/50000]\n",
            "loss: 1.126312  [ 8336/50000]\n",
            "loss: 0.784197  [16656/50000]\n",
            "loss: 1.041040  [24976/50000]\n",
            "loss: 1.166911  [33296/50000]\n",
            "loss: 1.413109  [41616/50000]\n",
            "loss: 1.008399  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 71.2%, Avg loss: 0.817855 \n",
            "\n",
            "Epoch 25 \n",
            "-------------------------------\n",
            "loss: 0.466078  [   16/50000]\n",
            "loss: 0.899918  [ 8336/50000]\n",
            "loss: 0.628888  [16656/50000]\n",
            "loss: 0.944277  [24976/50000]\n",
            "loss: 0.984046  [33296/50000]\n",
            "loss: 0.445169  [41616/50000]\n",
            "loss: 1.287581  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 72.9%, Avg loss: 0.767344 \n",
            "\n",
            "Epoch 26 \n",
            "-------------------------------\n",
            "loss: 0.718802  [   16/50000]\n",
            "loss: 0.710595  [ 8336/50000]\n",
            "loss: 0.497045  [16656/50000]\n",
            "loss: 1.312747  [24976/50000]\n",
            "loss: 1.018406  [33296/50000]\n",
            "loss: 0.883353  [41616/50000]\n",
            "loss: 0.885633  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 73.1%, Avg loss: 0.780007 \n",
            "\n",
            "Epoch 27 \n",
            "-------------------------------\n",
            "loss: 0.561976  [   16/50000]\n",
            "loss: 0.654463  [ 8336/50000]\n",
            "loss: 0.667102  [16656/50000]\n",
            "loss: 1.189418  [24976/50000]\n",
            "loss: 1.397244  [33296/50000]\n",
            "loss: 0.517627  [41616/50000]\n",
            "loss: 0.835989  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 73.4%, Avg loss: 0.758936 \n",
            "\n",
            "Epoch 28 \n",
            "-------------------------------\n",
            "loss: 0.878938  [   16/50000]\n",
            "loss: 0.791138  [ 8336/50000]\n",
            "loss: 0.645395  [16656/50000]\n",
            "loss: 0.671940  [24976/50000]\n",
            "loss: 0.435224  [33296/50000]\n",
            "loss: 1.137175  [41616/50000]\n",
            "loss: 0.501021  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 74.0%, Avg loss: 0.750129 \n",
            "\n",
            "Epoch 29 \n",
            "-------------------------------\n",
            "loss: 0.377375  [   16/50000]\n",
            "loss: 0.671188  [ 8336/50000]\n",
            "loss: 0.797929  [16656/50000]\n",
            "loss: 0.669319  [24976/50000]\n",
            "loss: 0.737557  [33296/50000]\n",
            "loss: 0.757498  [41616/50000]\n",
            "loss: 1.361232  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 73.8%, Avg loss: 0.757437 \n",
            "\n",
            "Epoch 30 \n",
            "-------------------------------\n",
            "loss: 0.780149  [   16/50000]\n",
            "loss: 0.885239  [ 8336/50000]\n",
            "loss: 0.576904  [16656/50000]\n",
            "loss: 0.872350  [24976/50000]\n",
            "loss: 0.444554  [33296/50000]\n",
            "loss: 0.539090  [41616/50000]\n",
            "loss: 1.117711  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 74.5%, Avg loss: 0.736737 \n",
            "\n",
            "Epoch 31 \n",
            "-------------------------------\n",
            "loss: 1.361257  [   16/50000]\n",
            "loss: 0.900828  [ 8336/50000]\n",
            "loss: 1.058719  [16656/50000]\n",
            "loss: 0.612520  [24976/50000]\n",
            "loss: 0.386251  [33296/50000]\n",
            "loss: 1.007962  [41616/50000]\n",
            "loss: 0.518633  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 74.7%, Avg loss: 0.725055 \n",
            "\n",
            "Epoch 32 \n",
            "-------------------------------\n",
            "loss: 1.005123  [   16/50000]\n",
            "loss: 0.941411  [ 8336/50000]\n",
            "loss: 1.185356  [16656/50000]\n",
            "loss: 0.555960  [24976/50000]\n",
            "loss: 1.243121  [33296/50000]\n",
            "loss: 0.668535  [41616/50000]\n",
            "loss: 0.789644  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 75.3%, Avg loss: 0.711376 \n",
            "\n",
            "Epoch 33 \n",
            "-------------------------------\n",
            "loss: 0.655356  [   16/50000]\n",
            "loss: 0.427725  [ 8336/50000]\n",
            "loss: 0.781298  [16656/50000]\n",
            "loss: 0.585804  [24976/50000]\n",
            "loss: 0.759834  [33296/50000]\n",
            "loss: 0.575112  [41616/50000]\n",
            "loss: 0.643740  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 74.4%, Avg loss: 0.746580 \n",
            "\n",
            "Epoch 34 \n",
            "-------------------------------\n",
            "loss: 0.500222  [   16/50000]\n",
            "loss: 0.464601  [ 8336/50000]\n",
            "loss: 0.373336  [16656/50000]\n",
            "loss: 0.583113  [24976/50000]\n",
            "loss: 0.788116  [33296/50000]\n",
            "loss: 0.756245  [41616/50000]\n",
            "loss: 0.492136  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 75.4%, Avg loss: 0.712577 \n",
            "\n",
            "Epoch 35 \n",
            "-------------------------------\n",
            "loss: 0.767823  [   16/50000]\n",
            "loss: 0.899989  [ 8336/50000]\n",
            "loss: 0.677826  [16656/50000]\n",
            "loss: 1.364578  [24976/50000]\n",
            "loss: 0.201406  [33296/50000]\n",
            "loss: 0.492504  [41616/50000]\n",
            "loss: 0.614336  [49936/50000]\n",
            "Test error: \n",
            " Accuracy: 75.5%, Avg loss: 0.709711 \n",
            "\n",
            "Epoch 36 \n",
            "-------------------------------\n",
            "loss: 0.626978  [   16/50000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-415a66a2daea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1} \\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done :)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-e2a37efced1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimiser)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
