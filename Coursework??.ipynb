{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqnGfa63DgvlNYXCS65qxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkyHaines/IMLO/blob/main/Coursework%3F%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CIFAR 10 dataset contains 60,000 3x32x32 colour images, with 10 classes."
      ],
      "metadata": {
        "id": "-84D_fD6rDLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Need to look into how this works, perhaps i could tweak it to improve accuracy?\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download training and testing data\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "VZi8zCXJrav8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I need to experiment with batch size. (The number of images processed before updating the weights).\n",
        "\n",
        "As I understand it,\n",
        "Larger batch size : Faster training, lower accuracy\n",
        "Smaller batch size: Slower training, higher accuracy\n",
        "\n",
        "So I'm going to do some trial and error I think, to get the batch size at a point where I use up just under the whole 4 training hours, with the highest accuracy :)\n",
        "\n",
        "Contextualise: There are 50,000 training imgs, so I'm going to try a batch size of 100 for now? (As its a multiple, I assume it helps somehow?)\n",
        "UPDATED: Changed to 64, research suggests it helps with runtime to have it as a power of 2, for parallelism. Will take this into account for further optimisation."
      ],
      "metadata": {
        "id": "1fwoUvIGtKON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "MgLYf_Y9uPpl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I need to define the nn architecture/structure? I think I need to use a CNN rather than a regular NN because it's for images rather than numerical data"
      ],
      "metadata": {
        "id": "g1c8jRGF4Rz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # First layer? Has 3 input channels due to RGB\n",
        "    # input tensor = size of prev layer output * filters in prev layer\n",
        "    # output tensor = size of input img * filters\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=2, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels= 12,kernel_size=2, stride=1, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*8*8, out_features=128)\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool2(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = MyCNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkfUE5N64dPX",
        "outputId": "c8903715-9ea0-4761-b5d4-9010112be268"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyCNN(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "8qP-BYDG9P3o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimiser):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "HfS2EQkC-5SR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n-------------------------------\")\n",
        "  train(train_dataloader, model, loss, optimiser)\n",
        "  test(test_dataloader, model, loss)\n",
        "print(\"Done :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSwKwo58_VLm",
        "outputId": "bce6bbb4-387d-4a79-a216-c8ed410c6ae4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "-------------------------------\n",
            "loss: 2.316995  [   64/50000]\n",
            "loss: 2.297624  [ 6464/50000]\n",
            "loss: 2.306863  [12864/50000]\n",
            "loss: 2.291114  [19264/50000]\n",
            "loss: 2.315272  [25664/50000]\n",
            "loss: 2.304641  [32064/50000]\n",
            "loss: 2.294323  [38464/50000]\n",
            "loss: 2.302375  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 11.4%, Avg loss: 2.300893 \n",
            "\n",
            "Epoch 2 \n",
            "-------------------------------\n",
            "loss: 2.304655  [   64/50000]\n",
            "loss: 2.304469  [ 6464/50000]\n",
            "loss: 2.301111  [12864/50000]\n",
            "loss: 2.298254  [19264/50000]\n",
            "loss: 2.296534  [25664/50000]\n",
            "loss: 2.290886  [32064/50000]\n",
            "loss: 2.300788  [38464/50000]\n",
            "loss: 2.297734  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 12.6%, Avg loss: 2.295924 \n",
            "\n",
            "Epoch 3 \n",
            "-------------------------------\n",
            "loss: 2.288890  [   64/50000]\n",
            "loss: 2.292371  [ 6464/50000]\n",
            "loss: 2.293914  [12864/50000]\n",
            "loss: 2.300727  [19264/50000]\n",
            "loss: 2.291284  [25664/50000]\n",
            "loss: 2.292559  [32064/50000]\n",
            "loss: 2.284434  [38464/50000]\n",
            "loss: 2.285740  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 14.6%, Avg loss: 2.289032 \n",
            "\n",
            "Epoch 4 \n",
            "-------------------------------\n",
            "loss: 2.294749  [   64/50000]\n",
            "loss: 2.282739  [ 6464/50000]\n",
            "loss: 2.278372  [12864/50000]\n",
            "loss: 2.284437  [19264/50000]\n",
            "loss: 2.280385  [25664/50000]\n",
            "loss: 2.281921  [32064/50000]\n",
            "loss: 2.281875  [38464/50000]\n",
            "loss: 2.279409  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 17.4%, Avg loss: 2.277717 \n",
            "\n",
            "Epoch 5 \n",
            "-------------------------------\n",
            "loss: 2.274979  [   64/50000]\n",
            "loss: 2.280569  [ 6464/50000]\n",
            "loss: 2.264459  [12864/50000]\n",
            "loss: 2.259816  [19264/50000]\n",
            "loss: 2.262148  [25664/50000]\n",
            "loss: 2.258752  [32064/50000]\n",
            "loss: 2.261089  [38464/50000]\n",
            "loss: 2.268863  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 20.2%, Avg loss: 2.257849 \n",
            "\n",
            "Epoch 6 \n",
            "-------------------------------\n",
            "loss: 2.268617  [   64/50000]\n",
            "loss: 2.280677  [ 6464/50000]\n",
            "loss: 2.265529  [12864/50000]\n",
            "loss: 2.246091  [19264/50000]\n",
            "loss: 2.236963  [25664/50000]\n",
            "loss: 2.239277  [32064/50000]\n",
            "loss: 2.240767  [38464/50000]\n",
            "loss: 2.240285  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 22.0%, Avg loss: 2.222614 \n",
            "\n",
            "Epoch 7 \n",
            "-------------------------------\n",
            "loss: 2.229078  [   64/50000]\n",
            "loss: 2.201409  [ 6464/50000]\n",
            "loss: 2.230624  [12864/50000]\n",
            "loss: 2.226727  [19264/50000]\n",
            "loss: 2.212539  [25664/50000]\n",
            "loss: 2.152924  [32064/50000]\n",
            "loss: 2.221061  [38464/50000]\n",
            "loss: 2.163329  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 23.9%, Avg loss: 2.168398 \n",
            "\n",
            "Epoch 8 \n",
            "-------------------------------\n",
            "loss: 2.179982  [   64/50000]\n",
            "loss: 2.178954  [ 6464/50000]\n",
            "loss: 2.168063  [12864/50000]\n",
            "loss: 2.142343  [19264/50000]\n",
            "loss: 2.125045  [25664/50000]\n",
            "loss: 2.099352  [32064/50000]\n",
            "loss: 2.116488  [38464/50000]\n",
            "loss: 2.103664  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 26.0%, Avg loss: 2.110996 \n",
            "\n",
            "Epoch 9 \n",
            "-------------------------------\n",
            "loss: 2.111584  [   64/50000]\n",
            "loss: 2.080863  [ 6464/50000]\n",
            "loss: 2.128951  [12864/50000]\n",
            "loss: 2.133492  [19264/50000]\n",
            "loss: 2.099571  [25664/50000]\n",
            "loss: 1.999810  [32064/50000]\n",
            "loss: 1.973971  [38464/50000]\n",
            "loss: 2.078666  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 27.6%, Avg loss: 2.068966 \n",
            "\n",
            "Epoch 10 \n",
            "-------------------------------\n",
            "loss: 2.049786  [   64/50000]\n",
            "loss: 2.138357  [ 6464/50000]\n",
            "loss: 2.099796  [12864/50000]\n",
            "loss: 2.004653  [19264/50000]\n",
            "loss: 2.007134  [25664/50000]\n",
            "loss: 2.146504  [32064/50000]\n",
            "loss: 2.138966  [38464/50000]\n",
            "loss: 2.034784  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 28.5%, Avg loss: 2.037451 \n",
            "\n",
            "Epoch 11 \n",
            "-------------------------------\n",
            "loss: 2.065311  [   64/50000]\n",
            "loss: 1.931862  [ 6464/50000]\n",
            "loss: 1.986780  [12864/50000]\n",
            "loss: 1.970334  [19264/50000]\n",
            "loss: 2.221459  [25664/50000]\n",
            "loss: 1.984519  [32064/50000]\n",
            "loss: 2.027289  [38464/50000]\n",
            "loss: 2.065012  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 29.9%, Avg loss: 2.009172 \n",
            "\n",
            "Epoch 12 \n",
            "-------------------------------\n",
            "loss: 1.886224  [   64/50000]\n",
            "loss: 1.955234  [ 6464/50000]\n",
            "loss: 2.023635  [12864/50000]\n",
            "loss: 2.024745  [19264/50000]\n",
            "loss: 2.187990  [25664/50000]\n",
            "loss: 2.036924  [32064/50000]\n",
            "loss: 1.824252  [38464/50000]\n",
            "loss: 2.092935  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 31.6%, Avg loss: 1.982902 \n",
            "\n",
            "Epoch 13 \n",
            "-------------------------------\n",
            "loss: 2.066788  [   64/50000]\n",
            "loss: 1.868443  [ 6464/50000]\n",
            "loss: 2.018443  [12864/50000]\n",
            "loss: 1.942347  [19264/50000]\n",
            "loss: 2.039899  [25664/50000]\n",
            "loss: 2.013290  [32064/50000]\n",
            "loss: 2.001069  [38464/50000]\n",
            "loss: 1.843813  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 32.6%, Avg loss: 1.956069 \n",
            "\n",
            "Epoch 14 \n",
            "-------------------------------\n",
            "loss: 2.076433  [   64/50000]\n",
            "loss: 1.957918  [ 6464/50000]\n",
            "loss: 1.986587  [12864/50000]\n",
            "loss: 2.109486  [19264/50000]\n",
            "loss: 1.858395  [25664/50000]\n",
            "loss: 1.937355  [32064/50000]\n",
            "loss: 1.878019  [38464/50000]\n",
            "loss: 1.930406  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 33.4%, Avg loss: 1.928384 \n",
            "\n",
            "Epoch 15 \n",
            "-------------------------------\n",
            "loss: 1.797080  [   64/50000]\n",
            "loss: 1.883215  [ 6464/50000]\n",
            "loss: 1.954797  [12864/50000]\n",
            "loss: 1.973796  [19264/50000]\n",
            "loss: 2.087348  [25664/50000]\n",
            "loss: 1.857664  [32064/50000]\n",
            "loss: 1.847365  [38464/50000]\n",
            "loss: 1.869462  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 34.5%, Avg loss: 1.899350 \n",
            "\n",
            "Epoch 16 \n",
            "-------------------------------\n",
            "loss: 1.811783  [   64/50000]\n",
            "loss: 1.798278  [ 6464/50000]\n",
            "loss: 1.843145  [12864/50000]\n",
            "loss: 1.820163  [19264/50000]\n",
            "loss: 1.846192  [25664/50000]\n",
            "loss: 1.656545  [32064/50000]\n",
            "loss: 1.813168  [38464/50000]\n",
            "loss: 1.807469  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 35.4%, Avg loss: 1.870314 \n",
            "\n",
            "Epoch 17 \n",
            "-------------------------------\n",
            "loss: 1.875085  [   64/50000]\n",
            "loss: 1.945849  [ 6464/50000]\n",
            "loss: 1.887358  [12864/50000]\n",
            "loss: 1.982305  [19264/50000]\n",
            "loss: 1.915983  [25664/50000]\n",
            "loss: 2.019342  [32064/50000]\n",
            "loss: 1.890015  [38464/50000]\n",
            "loss: 1.739788  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 36.2%, Avg loss: 1.841897 \n",
            "\n",
            "Epoch 18 \n",
            "-------------------------------\n",
            "loss: 1.797995  [   64/50000]\n",
            "loss: 1.830687  [ 6464/50000]\n",
            "loss: 1.825096  [12864/50000]\n",
            "loss: 1.913306  [19264/50000]\n",
            "loss: 1.917345  [25664/50000]\n",
            "loss: 1.809916  [32064/50000]\n",
            "loss: 1.821196  [38464/50000]\n",
            "loss: 2.011704  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 36.9%, Avg loss: 1.813046 \n",
            "\n",
            "Epoch 19 \n",
            "-------------------------------\n",
            "loss: 1.778921  [   64/50000]\n",
            "loss: 1.969033  [ 6464/50000]\n",
            "loss: 1.637462  [12864/50000]\n",
            "loss: 1.800808  [19264/50000]\n",
            "loss: 1.750564  [25664/50000]\n",
            "loss: 1.855675  [32064/50000]\n",
            "loss: 1.669185  [38464/50000]\n",
            "loss: 1.705784  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 37.8%, Avg loss: 1.787318 \n",
            "\n",
            "Epoch 20 \n",
            "-------------------------------\n",
            "loss: 2.006531  [   64/50000]\n",
            "loss: 1.759697  [ 6464/50000]\n",
            "loss: 1.848105  [12864/50000]\n",
            "loss: 1.889961  [19264/50000]\n",
            "loss: 1.909479  [25664/50000]\n",
            "loss: 1.793193  [32064/50000]\n",
            "loss: 1.653495  [38464/50000]\n",
            "loss: 1.723122  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 38.3%, Avg loss: 1.765611 \n",
            "\n",
            "Epoch 21 \n",
            "-------------------------------\n",
            "loss: 1.802061  [   64/50000]\n",
            "loss: 1.767742  [ 6464/50000]\n",
            "loss: 1.720683  [12864/50000]\n",
            "loss: 1.890421  [19264/50000]\n",
            "loss: 1.812820  [25664/50000]\n",
            "loss: 1.648597  [32064/50000]\n",
            "loss: 1.644764  [38464/50000]\n",
            "loss: 1.666947  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 38.9%, Avg loss: 1.745990 \n",
            "\n",
            "Epoch 22 \n",
            "-------------------------------\n",
            "loss: 1.702935  [   64/50000]\n",
            "loss: 1.940257  [ 6464/50000]\n",
            "loss: 1.733210  [12864/50000]\n",
            "loss: 1.876334  [19264/50000]\n",
            "loss: 1.804591  [25664/50000]\n",
            "loss: 1.780976  [32064/50000]\n",
            "loss: 1.616700  [38464/50000]\n",
            "loss: 1.738402  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 39.4%, Avg loss: 1.729855 \n",
            "\n",
            "Epoch 23 \n",
            "-------------------------------\n",
            "loss: 1.809191  [   64/50000]\n",
            "loss: 1.778450  [ 6464/50000]\n",
            "loss: 1.651176  [12864/50000]\n",
            "loss: 1.688099  [19264/50000]\n",
            "loss: 1.949498  [25664/50000]\n",
            "loss: 1.698877  [32064/50000]\n",
            "loss: 1.737508  [38464/50000]\n",
            "loss: 1.708118  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 39.6%, Avg loss: 1.716551 \n",
            "\n",
            "Epoch 24 \n",
            "-------------------------------\n",
            "loss: 1.827880  [   64/50000]\n",
            "loss: 1.810817  [ 6464/50000]\n",
            "loss: 1.644670  [12864/50000]\n",
            "loss: 1.786568  [19264/50000]\n",
            "loss: 1.717451  [25664/50000]\n",
            "loss: 1.697459  [32064/50000]\n",
            "loss: 1.566242  [38464/50000]\n",
            "loss: 1.747585  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 40.4%, Avg loss: 1.700221 \n",
            "\n",
            "Epoch 25 \n",
            "-------------------------------\n",
            "loss: 1.928174  [   64/50000]\n",
            "loss: 1.715446  [ 6464/50000]\n",
            "loss: 1.669344  [12864/50000]\n",
            "loss: 1.602195  [19264/50000]\n",
            "loss: 1.554258  [25664/50000]\n",
            "loss: 1.632793  [32064/50000]\n",
            "loss: 1.588961  [38464/50000]\n",
            "loss: 1.608626  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 40.7%, Avg loss: 1.686483 \n",
            "\n",
            "Done :)\n"
          ]
        }
      ]
    }
  ]
}