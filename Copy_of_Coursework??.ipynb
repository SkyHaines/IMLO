{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxmxxvehJF9llJ10WQCG9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkyHaines/IMLO/blob/main/Copy_of_Coursework%3F%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CIFAR 10 dataset contains 60,000 3x32x32 colour images, with 10 classes."
      ],
      "metadata": {
        "id": "-84D_fD6rDLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Need to look into how this works, perhaps i could tweak it to improve accuracy?\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.3),\n",
        "     transforms.RandomVerticalFlip(p=0.3),\n",
        "     transforms.RandomCrop(32, padding=3),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download training and testing data\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "VZi8zCXJrav8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I need to experiment with batch size. (The number of images processed before updating the weights).\n",
        "\n",
        "As I understand it,\n",
        "Larger batch size : Faster training, lower accuracy\n",
        "Smaller batch size: Slower training, higher accuracy\n",
        "\n",
        "So I'm going to do some trial and error I think, to get the batch size at a point where I use up just under the whole 4 training hours, with the highest accuracy :)\n",
        "\n",
        "Contextualise: There are 50,000 training imgs, so I'm going to try a batch size of 100 for now? (As its a multiple, I assume it helps somehow?)\n",
        "UPDATED: Changed to 64, research suggests it helps with runtime to have it as a power of 2, for parallelism. Will take this into account for further optimisation."
      ],
      "metadata": {
        "id": "1fwoUvIGtKON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "MgLYf_Y9uPpl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I need to define the nn architecture/structure? I think I need to use a CNN rather than a regular NN because it's for images rather than numerical data"
      ],
      "metadata": {
        "id": "g1c8jRGF4Rz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # First layer? Has 3 input channels due to RGB\n",
        "    # input tensor = size of prev layer output * filters in prev layer\n",
        "    # output tensor = size of input img * filters\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=8, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=24, out_channels=48,kernel_size=4, stride=1, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=96*3*3, out_features=512)\n",
        "    self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
        "    self.fc3 = nn.Linear(in_features=256, out_features=128)\n",
        "    self.fc4 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool3(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "model = MyCNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkfUE5N64dPX",
        "outputId": "203c4557-d62f-4070-e1d6-660d5e732e7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyCNN(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(24, 48, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=864, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "8qP-BYDG9P3o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimiser):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      if batch % 250 == 0:\n",
        "        loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "HfS2EQkC-5SR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n-------------------------------\")\n",
        "  train(train_dataloader, model, loss, optimiser)\n",
        "  test(test_dataloader, model, loss)\n",
        "print(\"Done :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qSwKwo58_VLm",
        "outputId": "de65c531-696e-438d-a4f7-9edcc2d8fd9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "-------------------------------\n",
            "loss: 2.302409  [   32/50000]\n",
            "loss: 2.073208  [ 8032/50000]\n",
            "loss: 1.726287  [16032/50000]\n",
            "loss: 1.720847  [24032/50000]\n",
            "loss: 1.895819  [32032/50000]\n",
            "loss: 1.914840  [40032/50000]\n",
            "loss: 1.575465  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 40.2%, Avg loss: 1.615321 \n",
            "\n",
            "Epoch 2 \n",
            "-------------------------------\n",
            "loss: 1.581308  [   32/50000]\n",
            "loss: 1.285224  [ 8032/50000]\n",
            "loss: 1.689731  [16032/50000]\n",
            "loss: 1.609131  [24032/50000]\n",
            "loss: 1.601531  [32032/50000]\n",
            "loss: 1.319324  [40032/50000]\n",
            "loss: 1.572883  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 44.5%, Avg loss: 1.506191 \n",
            "\n",
            "Epoch 3 \n",
            "-------------------------------\n",
            "loss: 1.298484  [   32/50000]\n",
            "loss: 1.746323  [ 8032/50000]\n",
            "loss: 1.910259  [16032/50000]\n",
            "loss: 1.511642  [24032/50000]\n",
            "loss: 1.321030  [32032/50000]\n",
            "loss: 1.594055  [40032/50000]\n",
            "loss: 1.491163  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 46.9%, Avg loss: 1.429495 \n",
            "\n",
            "Epoch 4 \n",
            "-------------------------------\n",
            "loss: 1.653895  [   32/50000]\n",
            "loss: 1.430510  [ 8032/50000]\n",
            "loss: 1.387699  [16032/50000]\n",
            "loss: 1.240999  [24032/50000]\n",
            "loss: 1.341970  [32032/50000]\n",
            "loss: 1.482330  [40032/50000]\n",
            "loss: 1.510456  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 49.9%, Avg loss: 1.363660 \n",
            "\n",
            "Epoch 5 \n",
            "-------------------------------\n",
            "loss: 1.290691  [   32/50000]\n",
            "loss: 1.360901  [ 8032/50000]\n",
            "loss: 1.494291  [16032/50000]\n",
            "loss: 1.761707  [24032/50000]\n",
            "loss: 1.260798  [32032/50000]\n",
            "loss: 1.597497  [40032/50000]\n",
            "loss: 1.043282  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 51.9%, Avg loss: 1.314885 \n",
            "\n",
            "Epoch 6 \n",
            "-------------------------------\n",
            "loss: 1.203590  [   32/50000]\n",
            "loss: 1.346697  [ 8032/50000]\n",
            "loss: 1.279632  [16032/50000]\n",
            "loss: 1.599228  [24032/50000]\n",
            "loss: 1.428105  [32032/50000]\n",
            "loss: 1.166549  [40032/50000]\n",
            "loss: 1.384050  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 53.8%, Avg loss: 1.268121 \n",
            "\n",
            "Epoch 7 \n",
            "-------------------------------\n",
            "loss: 1.178851  [   32/50000]\n",
            "loss: 1.349099  [ 8032/50000]\n",
            "loss: 1.056760  [16032/50000]\n",
            "loss: 1.492063  [24032/50000]\n",
            "loss: 1.564514  [32032/50000]\n",
            "loss: 1.269171  [40032/50000]\n",
            "loss: 1.336067  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 56.0%, Avg loss: 1.221361 \n",
            "\n",
            "Epoch 8 \n",
            "-------------------------------\n",
            "loss: 1.240750  [   32/50000]\n",
            "loss: 0.939419  [ 8032/50000]\n",
            "loss: 1.111071  [16032/50000]\n",
            "loss: 1.048261  [24032/50000]\n",
            "loss: 1.170271  [32032/50000]\n",
            "loss: 0.974106  [40032/50000]\n",
            "loss: 1.093486  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 56.2%, Avg loss: 1.205843 \n",
            "\n",
            "Epoch 9 \n",
            "-------------------------------\n",
            "loss: 1.097359  [   32/50000]\n",
            "loss: 1.458752  [ 8032/50000]\n",
            "loss: 1.544805  [16032/50000]\n",
            "loss: 1.524494  [24032/50000]\n",
            "loss: 1.014968  [32032/50000]\n",
            "loss: 1.658703  [40032/50000]\n",
            "loss: 0.845545  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 58.7%, Avg loss: 1.160623 \n",
            "\n",
            "Epoch 10 \n",
            "-------------------------------\n",
            "loss: 1.070084  [   32/50000]\n",
            "loss: 1.156874  [ 8032/50000]\n",
            "loss: 1.341461  [16032/50000]\n",
            "loss: 1.218358  [24032/50000]\n",
            "loss: 1.706020  [32032/50000]\n",
            "loss: 1.031385  [40032/50000]\n",
            "loss: 1.012268  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 57.8%, Avg loss: 1.161032 \n",
            "\n",
            "Epoch 11 \n",
            "-------------------------------\n",
            "loss: 1.208057  [   32/50000]\n",
            "loss: 1.477765  [ 8032/50000]\n",
            "loss: 1.377069  [16032/50000]\n",
            "loss: 0.597070  [24032/50000]\n",
            "loss: 0.969677  [32032/50000]\n",
            "loss: 1.122893  [40032/50000]\n",
            "loss: 1.393162  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 60.0%, Avg loss: 1.145687 \n",
            "\n",
            "Epoch 12 \n",
            "-------------------------------\n",
            "loss: 1.435073  [   32/50000]\n",
            "loss: 0.902019  [ 8032/50000]\n",
            "loss: 1.170737  [16032/50000]\n",
            "loss: 1.175632  [24032/50000]\n",
            "loss: 1.152661  [32032/50000]\n",
            "loss: 0.760991  [40032/50000]\n",
            "loss: 0.734325  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 60.6%, Avg loss: 1.111654 \n",
            "\n",
            "Epoch 13 \n",
            "-------------------------------\n",
            "loss: 1.105815  [   32/50000]\n",
            "loss: 0.995335  [ 8032/50000]\n",
            "loss: 1.078806  [16032/50000]\n",
            "loss: 0.939332  [24032/50000]\n",
            "loss: 0.997459  [32032/50000]\n",
            "loss: 1.276423  [40032/50000]\n",
            "loss: 0.856733  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 61.7%, Avg loss: 1.091258 \n",
            "\n",
            "Epoch 14 \n",
            "-------------------------------\n",
            "loss: 0.985697  [   32/50000]\n",
            "loss: 1.107486  [ 8032/50000]\n",
            "loss: 1.073795  [16032/50000]\n",
            "loss: 0.854638  [24032/50000]\n",
            "loss: 1.229621  [32032/50000]\n",
            "loss: 1.081674  [40032/50000]\n",
            "loss: 0.935257  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 61.4%, Avg loss: 1.078797 \n",
            "\n",
            "Epoch 15 \n",
            "-------------------------------\n",
            "loss: 0.896212  [   32/50000]\n",
            "loss: 1.004836  [ 8032/50000]\n",
            "loss: 1.148199  [16032/50000]\n",
            "loss: 1.004067  [24032/50000]\n",
            "loss: 0.657487  [32032/50000]\n",
            "loss: 0.920012  [40032/50000]\n",
            "loss: 0.899804  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 62.1%, Avg loss: 1.059694 \n",
            "\n",
            "Epoch 16 \n",
            "-------------------------------\n",
            "loss: 0.883993  [   32/50000]\n",
            "loss: 1.056229  [ 8032/50000]\n",
            "loss: 1.291891  [16032/50000]\n",
            "loss: 1.041985  [24032/50000]\n",
            "loss: 1.020405  [32032/50000]\n",
            "loss: 1.155110  [40032/50000]\n",
            "loss: 1.069684  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 63.3%, Avg loss: 1.037524 \n",
            "\n",
            "Epoch 17 \n",
            "-------------------------------\n",
            "loss: 0.898436  [   32/50000]\n",
            "loss: 0.911786  [ 8032/50000]\n",
            "loss: 1.058070  [16032/50000]\n",
            "loss: 0.938556  [24032/50000]\n",
            "loss: 0.928058  [32032/50000]\n",
            "loss: 1.375121  [40032/50000]\n",
            "loss: 1.084462  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 63.4%, Avg loss: 1.041061 \n",
            "\n",
            "Epoch 18 \n",
            "-------------------------------\n",
            "loss: 0.891500  [   32/50000]\n",
            "loss: 1.337724  [ 8032/50000]\n",
            "loss: 0.927255  [16032/50000]\n",
            "loss: 1.187743  [24032/50000]\n",
            "loss: 0.848771  [32032/50000]\n",
            "loss: 0.731393  [40032/50000]\n",
            "loss: 1.226379  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 63.6%, Avg loss: 1.019415 \n",
            "\n",
            "Epoch 19 \n",
            "-------------------------------\n",
            "loss: 1.256181  [   32/50000]\n",
            "loss: 1.011539  [ 8032/50000]\n",
            "loss: 0.748652  [16032/50000]\n",
            "loss: 0.960817  [24032/50000]\n",
            "loss: 1.202163  [32032/50000]\n",
            "loss: 1.112932  [40032/50000]\n",
            "loss: 0.693702  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 64.5%, Avg loss: 1.014136 \n",
            "\n",
            "Epoch 20 \n",
            "-------------------------------\n",
            "loss: 1.309097  [   32/50000]\n",
            "loss: 1.180132  [ 8032/50000]\n",
            "loss: 1.297947  [16032/50000]\n",
            "loss: 0.627196  [24032/50000]\n",
            "loss: 1.222334  [32032/50000]\n",
            "loss: 1.152553  [40032/50000]\n",
            "loss: 0.749383  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 64.3%, Avg loss: 1.017693 \n",
            "\n",
            "Epoch 21 \n",
            "-------------------------------\n",
            "loss: 1.406538  [   32/50000]\n",
            "loss: 0.929286  [ 8032/50000]\n",
            "loss: 1.010842  [16032/50000]\n",
            "loss: 1.046314  [24032/50000]\n",
            "loss: 0.783581  [32032/50000]\n",
            "loss: 0.847099  [40032/50000]\n",
            "loss: 1.092469  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 65.6%, Avg loss: 0.982616 \n",
            "\n",
            "Epoch 22 \n",
            "-------------------------------\n",
            "loss: 0.884671  [   32/50000]\n",
            "loss: 1.415561  [ 8032/50000]\n",
            "loss: 0.864350  [16032/50000]\n",
            "loss: 1.169092  [24032/50000]\n",
            "loss: 1.335518  [32032/50000]\n",
            "loss: 0.953796  [40032/50000]\n",
            "loss: 1.034679  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 65.6%, Avg loss: 0.984420 \n",
            "\n",
            "Epoch 23 \n",
            "-------------------------------\n",
            "loss: 0.881387  [   32/50000]\n",
            "loss: 1.045094  [ 8032/50000]\n",
            "loss: 1.109097  [16032/50000]\n",
            "loss: 1.320664  [24032/50000]\n",
            "loss: 1.202518  [32032/50000]\n",
            "loss: 1.222250  [40032/50000]\n",
            "loss: 1.027916  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 66.3%, Avg loss: 0.971166 \n",
            "\n",
            "Epoch 24 \n",
            "-------------------------------\n",
            "loss: 0.879360  [   32/50000]\n",
            "loss: 0.797819  [ 8032/50000]\n",
            "loss: 1.009229  [16032/50000]\n",
            "loss: 1.137638  [24032/50000]\n",
            "loss: 0.937597  [32032/50000]\n",
            "loss: 0.746146  [40032/50000]\n",
            "loss: 0.964831  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 66.7%, Avg loss: 0.954339 \n",
            "\n",
            "Epoch 25 \n",
            "-------------------------------\n",
            "loss: 0.791341  [   32/50000]\n",
            "loss: 0.769628  [ 8032/50000]\n",
            "loss: 0.772344  [16032/50000]\n",
            "loss: 0.884446  [24032/50000]\n",
            "loss: 0.989275  [32032/50000]\n",
            "loss: 0.750328  [40032/50000]\n",
            "loss: 1.006337  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 67.4%, Avg loss: 0.931421 \n",
            "\n",
            "Epoch 26 \n",
            "-------------------------------\n",
            "loss: 0.750055  [   32/50000]\n",
            "loss: 1.208962  [ 8032/50000]\n",
            "loss: 0.904257  [16032/50000]\n",
            "loss: 1.108781  [24032/50000]\n",
            "loss: 0.702377  [32032/50000]\n",
            "loss: 1.023968  [40032/50000]\n",
            "loss: 0.723106  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 66.1%, Avg loss: 0.943455 \n",
            "\n",
            "Epoch 27 \n",
            "-------------------------------\n",
            "loss: 0.886316  [   32/50000]\n",
            "loss: 0.846306  [ 8032/50000]\n",
            "loss: 0.730550  [16032/50000]\n",
            "loss: 1.130244  [24032/50000]\n",
            "loss: 0.544594  [32032/50000]\n",
            "loss: 0.756756  [40032/50000]\n",
            "loss: 0.840313  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 68.1%, Avg loss: 0.912647 \n",
            "\n",
            "Epoch 28 \n",
            "-------------------------------\n",
            "loss: 1.077372  [   32/50000]\n",
            "loss: 0.792380  [ 8032/50000]\n",
            "loss: 0.691244  [16032/50000]\n",
            "loss: 0.881381  [24032/50000]\n",
            "loss: 0.834107  [32032/50000]\n",
            "loss: 0.847437  [40032/50000]\n",
            "loss: 0.864077  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 68.2%, Avg loss: 0.895297 \n",
            "\n",
            "Epoch 29 \n",
            "-------------------------------\n",
            "loss: 0.984696  [   32/50000]\n",
            "loss: 0.497339  [ 8032/50000]\n",
            "loss: 1.107219  [16032/50000]\n",
            "loss: 1.233643  [24032/50000]\n",
            "loss: 0.644455  [32032/50000]\n",
            "loss: 0.485491  [40032/50000]\n",
            "loss: 1.057773  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 67.8%, Avg loss: 0.920184 \n",
            "\n",
            "Epoch 30 \n",
            "-------------------------------\n",
            "loss: 0.867780  [   32/50000]\n",
            "loss: 0.801350  [ 8032/50000]\n",
            "loss: 0.816551  [16032/50000]\n",
            "loss: 0.838063  [24032/50000]\n",
            "loss: 1.193906  [32032/50000]\n",
            "loss: 0.930881  [40032/50000]\n",
            "loss: 0.987648  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 69.1%, Avg loss: 0.882201 \n",
            "\n",
            "Epoch 31 \n",
            "-------------------------------\n",
            "loss: 0.705189  [   32/50000]\n",
            "loss: 1.143650  [ 8032/50000]\n",
            "loss: 0.611583  [16032/50000]\n",
            "loss: 0.563283  [24032/50000]\n",
            "loss: 0.601793  [32032/50000]\n",
            "loss: 1.175482  [40032/50000]\n",
            "loss: 0.814945  [48032/50000]\n",
            "Test error: \n",
            " Accuracy: 67.0%, Avg loss: 0.942254 \n",
            "\n",
            "Epoch 32 \n",
            "-------------------------------\n",
            "loss: 0.920106  [   32/50000]\n",
            "loss: 1.031692  [ 8032/50000]\n",
            "loss: 0.645591  [16032/50000]\n",
            "loss: 1.013446  [24032/50000]\n",
            "loss: 0.861923  [32032/50000]\n",
            "loss: 0.915816  [40032/50000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-db1f806fab1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1} \\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done :)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-bf266f01c6ff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimiser)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3324\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3143\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3144\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3145\u001b[0m         \u001b[0mdecoder_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mheight\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}