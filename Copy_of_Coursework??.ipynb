{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh7BrXt6TSHglZTCHOtVbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkyHaines/IMLO/blob/main/Copy_of_Coursework%3F%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CIFAR 10 dataset contains 60,000 3x32x32 colour images, with 10 classes."
      ],
      "metadata": {
        "id": "-84D_fD6rDLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Need to look into how this works, perhaps i could tweak it to improve accuracy?\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download training and testing data\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "VZi8zCXJrav8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16345562-0bf6-4b01-bbd5-6694b92d4173"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 76.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I need to experiment with batch size. (The number of images processed before updating the weights).\n",
        "\n",
        "As I understand it,\n",
        "Larger batch size : Faster training, lower accuracy\n",
        "Smaller batch size: Slower training, higher accuracy\n",
        "\n",
        "So I'm going to do some trial and error I think, to get the batch size at a point where I use up just under the whole 4 training hours, with the highest accuracy :)\n",
        "\n",
        "Contextualise: There are 50,000 training imgs, so I'm going to try a batch size of 100 for now? (As its a multiple, I assume it helps somehow?)\n",
        "UPDATED: Changed to 64, research suggests it helps with runtime to have it as a power of 2, for parallelism. Will take this into account for further optimisation."
      ],
      "metadata": {
        "id": "1fwoUvIGtKON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "MgLYf_Y9uPpl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I need to define the nn architecture/structure? I think I need to use a CNN rather than a regular NN because it's for images rather than numerical data"
      ],
      "metadata": {
        "id": "g1c8jRGF4Rz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # First layer? Has 3 input channels due to RGB\n",
        "    # input tensor = size of prev layer output * filters in prev layer\n",
        "    # output tensor = size of input img * filters\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=8, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=24, out_channels=48,kernel_size=4, stride=1, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=96*3*3, out_features=512)\n",
        "    self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
        "    self.fc3 = nn.Linear(in_features=256, out_features=128)\n",
        "    self.fc4 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool3(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "model = MyCNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkfUE5N64dPX",
        "outputId": "d091079c-1f2d-4f0e-b801-45bd82cc9d25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyCNN(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(24, 48, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=864, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "8qP-BYDG9P3o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimiser):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "HfS2EQkC-5SR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n-------------------------------\")\n",
        "  train(train_dataloader, model, loss, optimiser)\n",
        "  test(test_dataloader, model, loss)\n",
        "print(\"Done :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qSwKwo58_VLm",
        "outputId": "029661e0-b4c7-4fe6-b102-3f991b0675d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "-------------------------------\n",
            "loss: 2.301523  [   64/50000]\n",
            "loss: 1.792015  [ 6464/50000]\n",
            "loss: 1.589204  [12864/50000]\n",
            "loss: 1.590184  [19264/50000]\n",
            "loss: 1.370969  [25664/50000]\n",
            "loss: 1.373400  [32064/50000]\n",
            "loss: 1.482574  [38464/50000]\n",
            "loss: 1.192235  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 53.3%, Avg loss: 1.278532 \n",
            "\n",
            "Epoch 2 \n",
            "-------------------------------\n",
            "loss: 1.075395  [   64/50000]\n",
            "loss: 1.256635  [ 6464/50000]\n",
            "loss: 1.421484  [12864/50000]\n",
            "loss: 1.139790  [19264/50000]\n",
            "loss: 1.047006  [25664/50000]\n",
            "loss: 1.277868  [32064/50000]\n",
            "loss: 1.020124  [38464/50000]\n",
            "loss: 1.153665  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 60.0%, Avg loss: 1.131882 \n",
            "\n",
            "Epoch 3 \n",
            "-------------------------------\n",
            "loss: 0.894919  [   64/50000]\n",
            "loss: 1.009903  [ 6464/50000]\n",
            "loss: 0.829539  [12864/50000]\n",
            "loss: 1.114172  [19264/50000]\n",
            "loss: 0.889152  [25664/50000]\n",
            "loss: 0.758597  [32064/50000]\n",
            "loss: 1.017440  [38464/50000]\n",
            "loss: 1.028885  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 64.9%, Avg loss: 1.013412 \n",
            "\n",
            "Epoch 4 \n",
            "-------------------------------\n",
            "loss: 0.755997  [   64/50000]\n",
            "loss: 1.014437  [ 6464/50000]\n",
            "loss: 1.145644  [12864/50000]\n",
            "loss: 0.948910  [19264/50000]\n",
            "loss: 0.802150  [25664/50000]\n",
            "loss: 0.603909  [32064/50000]\n",
            "loss: 1.065451  [38464/50000]\n",
            "loss: 0.817360  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 66.1%, Avg loss: 0.992185 \n",
            "\n",
            "Epoch 5 \n",
            "-------------------------------\n",
            "loss: 0.805243  [   64/50000]\n",
            "loss: 1.094907  [ 6464/50000]\n",
            "loss: 0.917796  [12864/50000]\n",
            "loss: 0.528790  [19264/50000]\n",
            "loss: 0.756784  [25664/50000]\n",
            "loss: 0.873749  [32064/50000]\n",
            "loss: 0.825202  [38464/50000]\n",
            "loss: 0.617571  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 66.3%, Avg loss: 0.974017 \n",
            "\n",
            "Epoch 6 \n",
            "-------------------------------\n",
            "loss: 0.769468  [   64/50000]\n",
            "loss: 0.851472  [ 6464/50000]\n",
            "loss: 0.760537  [12864/50000]\n",
            "loss: 0.744078  [19264/50000]\n",
            "loss: 0.830141  [25664/50000]\n",
            "loss: 0.743688  [32064/50000]\n",
            "loss: 0.813749  [38464/50000]\n",
            "loss: 0.568986  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 68.8%, Avg loss: 0.926169 \n",
            "\n",
            "Epoch 7 \n",
            "-------------------------------\n",
            "loss: 0.512504  [   64/50000]\n",
            "loss: 0.678732  [ 6464/50000]\n",
            "loss: 0.749287  [12864/50000]\n",
            "loss: 0.957388  [19264/50000]\n",
            "loss: 0.867840  [25664/50000]\n",
            "loss: 0.705271  [32064/50000]\n",
            "loss: 0.556013  [38464/50000]\n",
            "loss: 0.880973  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 69.0%, Avg loss: 0.912671 \n",
            "\n",
            "Epoch 8 \n",
            "-------------------------------\n",
            "loss: 0.805191  [   64/50000]\n",
            "loss: 0.403057  [ 6464/50000]\n",
            "loss: 0.659199  [12864/50000]\n",
            "loss: 0.658600  [19264/50000]\n",
            "loss: 0.655812  [25664/50000]\n",
            "loss: 1.019771  [32064/50000]\n",
            "loss: 0.747986  [38464/50000]\n",
            "loss: 0.673388  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 69.6%, Avg loss: 0.927294 \n",
            "\n",
            "Epoch 9 \n",
            "-------------------------------\n",
            "loss: 0.642866  [   64/50000]\n",
            "loss: 0.381415  [ 6464/50000]\n",
            "loss: 0.742952  [12864/50000]\n",
            "loss: 0.442007  [19264/50000]\n",
            "loss: 0.370422  [25664/50000]\n",
            "loss: 0.566997  [32064/50000]\n",
            "loss: 0.654571  [38464/50000]\n",
            "loss: 0.613532  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 70.2%, Avg loss: 0.932268 \n",
            "\n",
            "Epoch 10 \n",
            "-------------------------------\n",
            "loss: 0.489787  [   64/50000]\n",
            "loss: 0.499718  [ 6464/50000]\n",
            "loss: 0.354884  [12864/50000]\n",
            "loss: 0.385851  [19264/50000]\n",
            "loss: 0.491004  [25664/50000]\n",
            "loss: 0.585476  [32064/50000]\n",
            "loss: 0.776537  [38464/50000]\n",
            "loss: 0.582895  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 68.7%, Avg loss: 1.002038 \n",
            "\n",
            "Epoch 11 \n",
            "-------------------------------\n",
            "loss: 0.357569  [   64/50000]\n",
            "loss: 0.510257  [ 6464/50000]\n",
            "loss: 0.499731  [12864/50000]\n",
            "loss: 0.642872  [19264/50000]\n",
            "loss: 0.620753  [25664/50000]\n",
            "loss: 0.504826  [32064/50000]\n",
            "loss: 0.414933  [38464/50000]\n",
            "loss: 0.512478  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 68.3%, Avg loss: 0.995288 \n",
            "\n",
            "Epoch 12 \n",
            "-------------------------------\n",
            "loss: 0.437621  [   64/50000]\n",
            "loss: 0.711827  [ 6464/50000]\n",
            "loss: 0.468375  [12864/50000]\n",
            "loss: 0.603615  [19264/50000]\n",
            "loss: 0.626394  [25664/50000]\n",
            "loss: 0.610560  [32064/50000]\n",
            "loss: 0.608490  [38464/50000]\n",
            "loss: 0.682344  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 68.9%, Avg loss: 1.039182 \n",
            "\n",
            "Epoch 13 \n",
            "-------------------------------\n",
            "loss: 0.383933  [   64/50000]\n",
            "loss: 0.398649  [ 6464/50000]\n",
            "loss: 0.379234  [12864/50000]\n",
            "loss: 0.598908  [19264/50000]\n",
            "loss: 0.451446  [25664/50000]\n",
            "loss: 0.358765  [32064/50000]\n",
            "loss: 0.510766  [38464/50000]\n",
            "loss: 0.655250  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 69.3%, Avg loss: 1.035349 \n",
            "\n",
            "Epoch 14 \n",
            "-------------------------------\n",
            "loss: 0.409637  [   64/50000]\n",
            "loss: 0.344275  [ 6464/50000]\n",
            "loss: 0.441091  [12864/50000]\n",
            "loss: 0.526167  [19264/50000]\n",
            "loss: 0.519683  [25664/50000]\n",
            "loss: 0.412775  [32064/50000]\n",
            "loss: 0.605256  [38464/50000]\n",
            "loss: 0.490152  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 68.6%, Avg loss: 1.072126 \n",
            "\n",
            "Epoch 15 \n",
            "-------------------------------\n",
            "loss: 0.317940  [   64/50000]\n",
            "loss: 0.320572  [ 6464/50000]\n",
            "loss: 0.482071  [12864/50000]\n",
            "loss: 0.150377  [19264/50000]\n",
            "loss: 0.476623  [25664/50000]\n",
            "loss: 0.512666  [32064/50000]\n",
            "loss: 0.532960  [38464/50000]\n",
            "loss: 0.534586  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 69.3%, Avg loss: 1.085245 \n",
            "\n",
            "Epoch 16 \n",
            "-------------------------------\n",
            "loss: 0.294893  [   64/50000]\n",
            "loss: 0.172786  [ 6464/50000]\n",
            "loss: 0.335336  [12864/50000]\n",
            "loss: 0.305687  [19264/50000]\n",
            "loss: 0.469300  [25664/50000]\n",
            "loss: 0.459016  [32064/50000]\n",
            "loss: 0.350321  [38464/50000]\n",
            "loss: 0.295735  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 69.8%, Avg loss: 1.103692 \n",
            "\n",
            "Epoch 17 \n",
            "-------------------------------\n",
            "loss: 0.281800  [   64/50000]\n",
            "loss: 0.360000  [ 6464/50000]\n",
            "loss: 0.281797  [12864/50000]\n",
            "loss: 0.238711  [19264/50000]\n",
            "loss: 0.690375  [25664/50000]\n",
            "loss: 0.444957  [32064/50000]\n",
            "loss: 0.404415  [38464/50000]\n",
            "loss: 0.417471  [44864/50000]\n",
            "Test error: \n",
            " Accuracy: 68.5%, Avg loss: 1.228015 \n",
            "\n",
            "Epoch 18 \n",
            "-------------------------------\n",
            "loss: 0.336322  [   64/50000]\n",
            "loss: 0.193721  [ 6464/50000]\n",
            "loss: 0.446196  [12864/50000]\n",
            "loss: 0.445525  [19264/50000]\n",
            "loss: 0.379115  [25664/50000]\n",
            "loss: 0.517652  [32064/50000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bc3217b284c1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1} \\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done :)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-5d03f4a6cbc1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimiser)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}